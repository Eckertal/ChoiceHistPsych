{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make super clean datafile!\n",
    "\n",
    "respecting the block structure and the fact that the first history columns within a block must be nans. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, glob\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "import operator\n",
    "\n",
    "# for frequentist model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "# settings for more convenient df inspection\n",
    "pd.set_option('display.max_columns',None)\n",
    "pd.set_option('display.max_rows',None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\annae\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3071: DtypeWarning: Columns (1) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    }
   ],
   "source": [
    "# i need a datafile that also has block type and difficulty level\n",
    "df_all = pd.read_csv('C:\\\\Users\\\\annae\\\\Desktop\\\\ChoiceHistory_Psych\\\\Data\\\\Exp1_auditory\\\\experimental_raw\\\\all_data_blind.csv', delimiter=';')\n",
    "subjects = list(df_all['Participant Private ID'].dropna().unique())\n",
    "\n",
    "pdi_res = pd.read_csv('C:\\\\Users\\\\annae\\\\Desktop\\\\ChoiceHistory_Psych\\\\Data\\\\Exp1_auditory\\\\psychosis_raw\\\\pdi_privateIDs.csv')\n",
    "caps_res = pd.read_csv('C:\\\\Users\\\\annae\\\\Desktop\\\\ChoiceHistory_Psych\\\\Data\\\\Exp1_auditory\\\\psychosis_raw\\\\caps_privateIDs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "148"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(subjects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Excluded:  34\n",
      "Included:  113\n"
     ]
    }
   ],
   "source": [
    "# EXCLUSIONS\n",
    "responses = ['Right', 'Left', '2500']\n",
    "exclusions, included = [], []\n",
    "\n",
    "for i in range(1, len(subjects)): \n",
    "    # exclude incomplete datasets\n",
    "    df_sbj = df_all[df_all['Participant Private ID'] == subjects[i]]\n",
    "    df_sbj_rel = df_sbj[df_sbj['Response'].isin(responses)]\n",
    "    \n",
    "    if df_sbj_rel.shape[0] != 385: \n",
    "        exclusions.append(subjects[i])\n",
    "        \n",
    "    # exclude performance based criterion\n",
    "    corr = df_sbj_rel['Correct'].value_counts()[1.0]\n",
    "    wron = df_sbj_rel['Correct'].value_counts()[0.0]\n",
    "    \n",
    "    perc = corr / (corr+wron)*100\n",
    "    \n",
    "    if perc > 90: \n",
    "        exclusions.append(subjects[i])\n",
    "    elif perc < 60: \n",
    "        exclusions.append(subjects[i])\n",
    "        \n",
    "    # exclude attention check missers\n",
    "    attention = df_sbj[df_sbj['Zone Type']=='response_keyboard_single']\n",
    "    attention_check_correct = attention.Correct.sum()\n",
    "    \n",
    "    if attention_check_correct < 20: \n",
    "        exclusions.append(subjects[i])\n",
    "        \n",
    "    # exclude ppl who didn't make it to the questionnaires\n",
    " \n",
    "    if caps_res[caps_res['Subject_ID']==subjects[i]].shape == (0,7): \n",
    "        exclusions.append(subjects[i])\n",
    "        \n",
    "    if pdi_res[pdi_res['Subject_ID']==subjects[i]].shape==(0,7):\n",
    "        exclusions.append(subjects[i])\n",
    "    \n",
    "    if subjects[i] not in exclusions: \n",
    "        included.append(df_sbj_rel)\n",
    "        \n",
    "df_inc = pd.concat(included)\n",
    "print('Excluded: ',len(set(exclusions)))\n",
    "print('Included: ',len(included))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['sbj_id','trial','block_type','block','stimulus','target','response','cue','caps','pdi']\n",
    "\n",
    "df_reg = pd.DataFrame(columns=cols)\n",
    "\n",
    "\n",
    "for df_sbj in included: \n",
    "    \n",
    "    block_ends = [49*i for i in range(1,9)]\n",
    "    trial_ct = 1\n",
    "    block_ct = 1\n",
    "    sbj_id = list(df_sbj['Participant Private ID'])[0]\n",
    "    \n",
    "    for index, row in df_sbj.iterrows(): \n",
    "        \n",
    "        if trial_ct in block_ends: \n",
    "            block_ct += 1\n",
    "            \n",
    "        # block_type\n",
    "        if row['meta_typeblock'] == 'rep': \n",
    "            block_type = 0\n",
    "        elif row['meta_typeblock'] == 'neut': \n",
    "            block_type = 1\n",
    "        \n",
    "        # cue\n",
    "        if row['cue'] == 'cue_right.PNG': \n",
    "            cue = 0 # right cue\n",
    "        elif row['cue'] == 'cue_left.PNG': \n",
    "            cue = 1 # left cue\n",
    "        else: \n",
    "            print('sth wrong')\n",
    "        \n",
    "        # stim, target, response\n",
    "        stim = row['meta_difflevel']/10 # in int dtype\n",
    "        target = row['ANSWER'] # correct answer\n",
    "        resp = row['Response'] # given answer\n",
    "\n",
    "        if target == 'Right': \n",
    "            target = 0\n",
    "        elif target == 'Left': \n",
    "            target = 1\n",
    "\n",
    "        if resp == 'Right': \n",
    "            resp = 0\n",
    "        elif resp == 'Left':\n",
    "            resp = 1\n",
    "        elif resp == '2500': # time-outs: I classify them as incorrect for now\n",
    "            \n",
    "            if target == 1: \n",
    "                resp = 0\n",
    "            elif target == 0: \n",
    "                resp = 1\n",
    "                \n",
    "        pdi = pdi_res[pdi_res['Subject_ID'] == sbj_id]['sum score'].values[0]\n",
    "        caps = caps_res[caps_res['Subject_ID'] == sbj_id]['sum score'].values[0]\n",
    "                \n",
    "        row = {'sbj_id':sbj_id,'trial':trial_ct,'block_type':block_type,'block':block_ct,\n",
    "               'stimulus':stim,'target':target,'response':resp,'cue':cue, 'pdi':pdi, 'caps':caps}\n",
    "        \n",
    "        df_reg = df_reg.append(row, ignore_index=True)\n",
    "        \n",
    "        trial_ct += 1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for full datafile as used in the incremental model comparison, change to range(1,8)\n",
    "hists = ['resp_%i'%i for i in range(1,2)]\n",
    "\n",
    "# make history columns with NaNs\n",
    "def make_nan_col(df, name): \n",
    "    df[name] = np.nan\n",
    "\n",
    "\n",
    "# collect previous k response and make them NaN at beginning of blocks\n",
    "def collect_history(df, k):\n",
    " \n",
    "    for index, row in df.iterrows():\n",
    "\n",
    "        prev = df[df.index==index-k]['response'].values.astype(int)\n",
    "\n",
    "        if prev.shape == (0,): \n",
    "            prev = np.nan\n",
    "            \n",
    "        elif df.at[index, 'block'] != df.at[index-1, 'block']: \n",
    "            prev = np.nan\n",
    "            \n",
    "        else: \n",
    "            prev = prev[0]\n",
    "            \n",
    "        target_col = str('resp_%i'%k)\n",
    "        df.at[index, target_col] = prev\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name in hists: \n",
    "    make_nan_col(df_reg, name)\n",
    "\n",
    "# reset index\n",
    "df = df_reg.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for full datafile as used in the incremental model comparison, change to range(1,8)\n",
    "for k in range(1,2): \n",
    "    collect_history(df, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_nans_history(df, k):\n",
    "    \n",
    "    target_col = 'resp_%i'%k\n",
    "    resps = [0.0, 1.0]\n",
    "    \n",
    "    indexes = []\n",
    "    \n",
    "    for index, row in df.iterrows():\n",
    "    \n",
    "        if df.at[index, target_col] not in resps:\n",
    "            indexes.append(index)\n",
    "            \n",
    "    for i in indexes: \n",
    "    \n",
    "        if i > 7:\n",
    "            \n",
    "            for j in range(1,k): \n",
    "\n",
    "                df.at[i+j, target_col] = np.nan\n",
    "              \n",
    "    return indexes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# add stimulus history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for full datafile as used in the incremental model comparison, change to range(1,8)\n",
    "stims = ['stim_%i'%i for i in range(1,2)]\n",
    "\n",
    "for stim in stims: \n",
    "    make_nan_col(df, stim)\n",
    "    \n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "# collect stimulus history and make it nan at block start\n",
    "def collect_history(df, k):\n",
    " \n",
    "    for index, row in df.iterrows():\n",
    "\n",
    "        prev = df[df.index==index-k]['target'].values.astype(int)\n",
    "        \n",
    "        if prev.shape == (0,): \n",
    "            prev = np.nan\n",
    "            \n",
    "        elif df.at[index, 'block'] != df.at[index-1, 'block']: \n",
    "            prev = np.nan\n",
    "            \n",
    "        else: \n",
    "            prev = prev[0]\n",
    "            \n",
    "        target_col = str('stim_%i'%k)\n",
    "        df.at[index, target_col] = prev\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for full datafile as used in the incremental model comparison, change to range(1,8)\n",
    "for k in range(1,2): \n",
    "    collect_history(df, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_nans_history(df, k):\n",
    "    \n",
    "    target_col = 'stim_%i'%k\n",
    "    stim = [0.0, 1.0]\n",
    "    \n",
    "    indexes = []\n",
    "    \n",
    "    for index, row in df.iterrows():\n",
    "    \n",
    "        if df.at[index, target_col] not in stim:\n",
    "            indexes.append(index)\n",
    "            \n",
    "    for i in indexes: \n",
    "    \n",
    "        if i > 7:\n",
    "            \n",
    "            for j in range(1,k): \n",
    "\n",
    "                df.at[i+j, target_col] = np.nan\n",
    "              \n",
    "    return indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for full datafile as used in the incremental model comparison, change to range(1,8)\n",
    "for k in range(1,2): \n",
    "    make_nans_history(df, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read super clean datafile that contains stimulus history as well.\n",
    "#os.chdir('C:\\\\Users\\\\annae\\\\Dropbox\\\\PhD\\\\CODE\\\\data_preprocessed')\n",
    "#df = pd.read_csv('final_clean_stimulus.csv')\n",
    "# drop random unnamed columns\n",
    "df = df.loc[:, ~df.columns.str.contains('^Unnamed')]\n",
    "\n",
    "# add PPS score, sum of z-standardized pdi and caps scores\n",
    "pps_measures = ['pdi', 'caps']\n",
    "\n",
    "for measure in pps_measures: \n",
    "    col_zscore = measure + '_zscore'\n",
    "    df[col_zscore] = (df[measure] - df[measure].mean())/df[measure].std(ddof=0)\n",
    "\n",
    "df['PPS_z'] = df['pdi_zscore'] + df['caps_zscore']\n",
    "\n",
    "\n",
    "# z-standardise columns\n",
    "cols = list(df.columns)\n",
    "[cols.remove(item) for item in ['sbj_id', 'trial', 'block', 'caps_zscore', 'pdi_zscore', 'PPS_z']]\n",
    "\n",
    "for col in cols: \n",
    "    col_z = col + '_z'\n",
    "    df[col_z] = (df[col]- df[col].mean())/df[col].std(ddof=0)\n",
    "    \n",
    "df = df.dropna()\n",
    "\n",
    "df.to_csv('1_model1_auditory.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
